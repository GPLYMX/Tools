{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bca602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import resnet34, resnet50, vgg11, resnet152, vgg19, vgg16, resnext101_32x8d, resnet18, \\\n",
    "    densenet201\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from visdom import Visdom\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7e6824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "        self.shape = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
    "        return x.view(-1, self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37c22641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfDefineModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SelfDefineModel, self).__init__()\n",
    "        self.trained_model = vgg16(pretrained=True)\n",
    "        self.modelA = nn.Sequential(*list(self.trained_model.children())[0][0:17],\n",
    "                                    nn.Conv2d(256, 64, kernel_size=(1, 1)),\n",
    "                                    nn.Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2),\n",
    "                                    nn.Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
    "                                    nn.Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
    "                                    nn.Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
    "                                    nn.AdaptiveAvgPool2d(output_size=(7, 7)),\n",
    "                                    Flatten(),\n",
    "                                    nn.Dropout(p=0.5),\n",
    "                                    nn.Linear(in_features=3136, out_features=512, bias=True),\n",
    "                                    # ChannelWise(3136, 512, device=torch.device('cuda'), input_split_size=4),\n",
    "                                    nn.Dropout(p=0.4),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Linear(512, 3),\n",
    "                                    nn.ReLU(inplace=True)\n",
    "                                    )\n",
    "        self.modelS = nn.Sequential(*list(self.trained_model.children())[0][0:23],\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False),\n",
    "                                    nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False),\n",
    "                                    nn.ConvTranspose2d(in_channels=512, out_channels=256, padding=2, kernel_size=8,\n",
    "                                                       stride=2),\n",
    "                                    nn.AdaptiveAvgPool2d(output_size=(7, 7)),\n",
    "                                    Flatten(),\n",
    "                                    nn.Linear(in_features=12544, out_features=512, bias=True),\n",
    "                                    # ChannelWise(12544, 512, device=torch.device('cuda'), input_split_size=8),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Dropout(p=0.5),\n",
    "                                    nn.Linear(512, 128),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Dropout(p=0.4),\n",
    "                                    nn.Linear(128, 16),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Dropout(p=0.3),\n",
    "                                    nn.Linear(16, 3)\n",
    "                                    )\n",
    "        self.vgg = nn.Sequential(*list(self.trained_model.children())[:-1],  # 测试一下输出维度[b, 512, 1, 1]\n",
    "                                 Flatten(),\n",
    "                                 nn.Linear(25088, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(p=0.4),\n",
    "                                 nn.Linear(512, 128),\n",
    "                                 nn.Dropout(p=0.3),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(128, 3)\n",
    "                                 )\n",
    "        self.model3 = nn.Sequential(\n",
    "            nn.Linear(18, 3)\n",
    "        )\n",
    "        self.trained_model2 = resnet34(pretrained=True)  # .to(device)\n",
    "        self.res34 = nn.Sequential(*list(self.trained_model2.children())[:-1],  # 测试一下输出维度[b, 512, 1, 1]\n",
    "                                   Flatten(),\n",
    "                                   nn.Dropout(p=0.5),\n",
    "                                   nn.Linear(512, 128),\n",
    "                                   nn.Dropout(p=0.4),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(128, 9)\n",
    "                                   )\n",
    "\n",
    "    def forward(self, input1):\n",
    "        x1 = self.modelA(input1)\n",
    "        x2 = self.modelS(input1)\n",
    "        x3 = self.vgg(input1)\n",
    "        x4 = self.res34(input1)\n",
    "        output1 = torch.cat([x1, x2, x3, x4], dim=1)\n",
    "        output1 = self.model3(output1)\n",
    "        return output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4919401",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SelfDefineModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "280009f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=3, bias=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.modelA[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ea3868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-5.5373e-01,  1.4270e-01,  5.2896e-01],\n",
      "          [-5.8312e-01,  3.5655e-01,  7.6566e-01],\n",
      "          [-6.9022e-01, -4.8019e-02,  4.8409e-01]],\n",
      "\n",
      "         [[ 1.7548e-01,  9.8630e-03, -8.1413e-02],\n",
      "          [ 4.4089e-02, -7.0323e-02, -2.6035e-01],\n",
      "          [ 1.3239e-01, -1.7279e-01, -1.3226e-01]],\n",
      "\n",
      "         [[ 3.1303e-01, -1.6591e-01, -4.2752e-01],\n",
      "          [ 4.7519e-01, -8.2677e-02, -4.8700e-01],\n",
      "          [ 6.3203e-01,  1.9308e-02, -2.7753e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3254e-01,  1.2666e-01,  1.8605e-01],\n",
      "          [-4.2805e-01, -2.4349e-01,  2.4628e-01],\n",
      "          [-2.5066e-01,  1.4177e-01, -5.4864e-03]],\n",
      "\n",
      "         [[-1.4076e-01, -2.1903e-01,  1.5041e-01],\n",
      "          [-8.4127e-01, -3.5176e-01,  5.6398e-01],\n",
      "          [-2.4194e-01,  5.1928e-01,  5.3915e-01]],\n",
      "\n",
      "         [[-3.1432e-01, -3.7048e-01, -1.3094e-01],\n",
      "          [-4.7144e-01, -1.5503e-01,  3.4589e-01],\n",
      "          [ 5.4384e-02,  5.8683e-01,  4.9580e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7715e-01,  5.2149e-01,  9.8740e-03],\n",
      "          [-2.7185e-01, -7.1709e-01,  3.1292e-01],\n",
      "          [-7.5753e-02, -2.2079e-01,  3.3455e-01]],\n",
      "\n",
      "         [[ 3.0924e-01,  6.7071e-01,  2.0546e-02],\n",
      "          [-4.6607e-01, -1.0697e+00,  3.3501e-01],\n",
      "          [-8.0284e-02, -3.0522e-01,  5.4460e-01]],\n",
      "\n",
      "         [[ 3.1572e-01,  4.2335e-01, -3.4976e-01],\n",
      "          [ 8.6354e-02, -4.6457e-01,  1.1803e-02],\n",
      "          [ 1.0483e-01, -1.4584e-01, -1.5765e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.7599e-02,  1.2692e-01,  3.2305e-02],\n",
      "          [ 2.2131e-01,  2.4681e-01, -4.6637e-02],\n",
      "          [ 4.6407e-02,  2.8246e-02,  1.7528e-02]],\n",
      "\n",
      "         [[-1.8327e-01, -6.7425e-02, -7.2120e-03],\n",
      "          [-4.8855e-02,  7.0427e-03, -1.2883e-01],\n",
      "          [-6.4601e-02, -6.4566e-02,  4.4235e-02]],\n",
      "\n",
      "         [[-2.2547e-01, -1.1931e-01, -2.3425e-02],\n",
      "          [-9.9171e-02, -1.5143e-02,  9.5385e-04],\n",
      "          [-2.6137e-02,  1.3567e-03,  1.4282e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6520e-02, -3.2225e-02, -3.8450e-03],\n",
      "          [-6.8206e-02, -1.9445e-01, -1.4166e-01],\n",
      "          [-6.9528e-02, -1.8340e-01, -1.7422e-01]],\n",
      "\n",
      "         [[ 4.2781e-02, -6.7529e-02, -7.0309e-03],\n",
      "          [ 1.1765e-02, -1.4958e-01, -1.2361e-01],\n",
      "          [ 1.0205e-02, -1.0393e-01, -1.1742e-01]],\n",
      "\n",
      "         [[ 1.2661e-01,  8.5046e-02,  1.3066e-01],\n",
      "          [ 1.7585e-01,  1.1288e-01,  1.1937e-01],\n",
      "          [ 1.4656e-01,  9.8892e-02,  1.0348e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2176e-02, -1.0766e-01, -2.6388e-01],\n",
      "          [ 2.7957e-01, -3.7416e-02, -2.5471e-01],\n",
      "          [ 3.4872e-01,  3.0041e-02, -5.5898e-02]],\n",
      "\n",
      "         [[ 2.5063e-01,  1.5543e-01, -1.7432e-01],\n",
      "          [ 3.9255e-01,  3.2306e-02, -3.5191e-01],\n",
      "          [ 1.9299e-01, -1.9898e-01, -2.9713e-01]],\n",
      "\n",
      "         [[ 4.6032e-01,  4.3399e-01,  2.8352e-01],\n",
      "          [ 1.6341e-01, -5.8165e-02, -1.9196e-01],\n",
      "          [-1.9521e-01, -4.5630e-01, -4.2732e-01]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4034,  0.3778,  0.4644, -0.3228,  0.3940, -0.3953,  0.3951, -0.5496,\n",
      "         0.2693, -0.7602, -0.3508,  0.2334, -1.3239, -0.1694,  0.3938, -0.1026,\n",
      "         0.0460, -0.6995,  0.1549,  0.5628,  0.3011,  0.3425,  0.1073,  0.4651,\n",
      "         0.1295,  0.0788, -0.0492, -0.5638,  0.1465, -0.3890, -0.0715,  0.0649,\n",
      "         0.2768,  0.3279,  0.5682, -1.2640, -0.8368, -0.9485,  0.1358,  0.2727,\n",
      "         0.1841, -0.5325,  0.3507, -0.0827, -1.0248, -0.6912, -0.7711,  0.2612,\n",
      "         0.4033, -0.4802, -0.3066,  0.5807, -1.3325,  0.4844, -0.8160,  0.2386,\n",
      "         0.2300,  0.4979,  0.5553,  0.5230, -0.2182,  0.0117, -0.5516,  0.2108],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for f in a.modelA[0].parameters():\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e804a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
