{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "_cell_guid": "96e001c5-6c5f-4247-b20c-c5de6b1b9276",
    "_uuid": "0faf75b2-9bc8-4389-9c6b-a5b7d6c6d1c6",
    "execution": {
     "iopub.execute_input": "2023-07-13T01:05:10.526351Z",
     "iopub.status.busy": "2023-07-13T01:05:10.525471Z",
     "iopub.status.idle": "2023-07-13T01:05:10.571105Z",
     "shell.execute_reply": "2023-07-13T01:05:10.569674Z",
     "shell.execute_reply.started": "2023-07-13T01:05:10.526307Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "_cell_guid": "5b0b7b96-53e4-4391-90c9-6ba8d89637d8",
    "_uuid": "46c19063-de36-4bf1-9731-f40dc4040346",
    "execution": {
     "iopub.execute_input": "2023-07-13T01:05:10.574324Z",
     "iopub.status.busy": "2023-07-13T01:05:10.573842Z",
     "iopub.status.idle": "2023-07-13T01:05:16.074991Z",
     "shell.execute_reply": "2023-07-13T01:05:16.073684Z",
     "shell.execute_reply.started": "2023-07-13T01:05:10.574251Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "_cell_guid": "b1de3b94-4c2e-47cc-afe6-6c845da63a55",
    "_uuid": "82efd7e9-cf6b-4c91-ba7e-6dc379a93f17",
    "execution": {
     "iopub.execute_input": "2023-07-13T01:05:16.077526Z",
     "iopub.status.busy": "2023-07-13T01:05:16.076950Z",
     "iopub.status.idle": "2023-07-13T01:05:16.134315Z",
     "shell.execute_reply": "2023-07-13T01:05:16.133343Z",
     "shell.execute_reply.started": "2023-07-13T01:05:16.077468Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('train.csv')\n",
    "dataset_df['EJ'] = dataset_df['EJ'].replace({'A':0, 'B':1})\n",
    "dataset_df = dataset_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "_cell_guid": "63d25949-03d0-4ee9-8e96-a1ca01976df6",
    "_uuid": "e5e17feb-657e-4ddb-9202-387eafe58aa3",
    "execution": {
     "iopub.execute_input": "2023-07-13T01:05:16.138685Z",
     "iopub.status.busy": "2023-07-13T01:05:16.137807Z",
     "iopub.status.idle": "2023-07-13T01:05:16.145843Z",
     "shell.execute_reply": "2023-07-13T01:05:16.143384Z",
     "shell.execute_reply.started": "2023-07-13T01:05:16.138634Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# feature_columns = dataset_df.columns[:-1]  # 假设最后一列为目标变量，不需要处理\n",
    "\n",
    "# # 针对每个特征列，将无穷大值替换为前 97% 大的值\n",
    "# for column in feature_columns:\n",
    "#     # 计算前 97% 大的值\n",
    "#     percentile = 0.98\n",
    "#     threshold = dataset_df[column].quantile(percentile)\n",
    "    \n",
    "#     # 将无穷大值替换为前 97% 大的值\n",
    "#     dataset_df[column] = dataset_df[column].replace(np.inf, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "_cell_guid": "8d7db594-4610-497b-b92f-c2a39d699566",
    "_uuid": "692cd51c-734f-495e-b1c7-cb51e1eca4a9",
    "execution": {
     "iopub.execute_input": "2023-07-13T01:05:16.148570Z",
     "iopub.status.busy": "2023-07-13T01:05:16.148126Z",
     "iopub.status.idle": "2023-07-13T01:05:16.197952Z",
     "shell.execute_reply": "2023-07-13T01:05:16.196962Z",
     "shell.execute_reply.started": "2023-07-13T01:05:16.148538Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 计算特征的均值、方差、标准差\n",
    "mean_values = dataset_df.mean()\n",
    "var_values = dataset_df.var()\n",
    "std_values = dataset_df.std()\n",
    "# 填充缺失值为特征的均值\n",
    "dataset_df = dataset_df.fillna(mean_values)\n",
    "max_values = dataset_df.max()\n",
    "min_values = dataset_df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "_cell_guid": "f27460e9-1331-44cd-bec7-2b03b659f31e",
    "_uuid": "3743f60e-c56e-4ff1-b95a-1f683bd4e296",
    "execution": {
     "iopub.execute_input": "2023-07-13T01:05:16.200917Z",
     "iopub.status.busy": "2023-07-13T01:05:16.199983Z",
     "iopub.status.idle": "2023-07-13T01:05:16.472332Z",
     "shell.execute_reply": "2023-07-13T01:05:16.470910Z",
     "shell.execute_reply.started": "2023-07-13T01:05:16.200870Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AB', 'AF', 'AH', 'AM', 'AX', 'BC', 'BD ', 'BN', 'BP', 'BQ', 'BR', 'CC',\n",
      "       'CD ', 'CF', 'CL', 'CR', 'CS', 'CU', 'CW ', 'DA', 'DE', 'DF', 'DH',\n",
      "       'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB', 'EE', 'EG', 'EH', 'EJ', 'EL',\n",
      "       'EP', 'EU', 'FC', 'FD ', 'FE', 'FI', 'FL', 'FR', 'FS', 'GB', 'GE', 'GF',\n",
      "       'GH', 'GI', 'GL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 分割特征和类别\n",
    "X = dataset_df.iloc[:, :-1]  # 特征\n",
    "y = dataset_df.iloc[:, -1]   # 类别\n",
    "# X = X.dropna()  # 删除包含缺失值的行\n",
    "y = y[X.index]  # 保持与特征对应的类别\n",
    "\n",
    "# 对非数值类型特征进行独热编码\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# 初始化特征选择器\n",
    "k = 50  # 选择前k个重要特征\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "\n",
    "# 特征选择\n",
    "X_selected = selector.fit_transform(X_encoded, y)\n",
    "\n",
    "# 获取选择的特征索引\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# 获取选择的特征名称\n",
    "selected_features = X_encoded.columns[selected_feature_indices]\n",
    "# selected_features = selected_features[:-2].append(pd.Index(['EJ']))\n",
    "# 输出选择的特征\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T01:05:16.475098Z",
     "iopub.status.busy": "2023-07-13T01:05:16.474241Z",
     "iopub.status.idle": "2023-07-13T01:05:16.492611Z",
     "shell.execute_reply": "2023-07-13T01:05:16.491127Z",
     "shell.execute_reply.started": "2023-07-13T01:05:16.475051Z"
    }
   },
   "outputs": [],
   "source": [
    "# 分割特征和类别\n",
    "X = dataset_df.iloc[:, :-1]  # 特征\n",
    "y = dataset_df.iloc[:, -1]   # 类别\n",
    "X = X.dropna()  # 删除包含缺失值的行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "_cell_guid": "17ec9259-5606-4101-bce4-29f367baa3c8",
    "_uuid": "04f2f20e-1b76-4943-b489-46af8ff82845",
    "execution": {
     "iopub.execute_input": "2023-07-13T01:05:16.495367Z",
     "iopub.status.busy": "2023-07-13T01:05:16.494447Z",
     "iopub.status.idle": "2023-07-13T01:05:16.506940Z",
     "shell.execute_reply": "2023-07-13T01:05:16.505205Z",
     "shell.execute_reply.started": "2023-07-13T01:05:16.495321Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = dataset_df.loc[:, selected_features], dataset_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X = np.array(X_train, dtype=np.float32)\n",
    "y = np.array(y_train, dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "# 转换为 PyTorch 的 Tensor 数据类型\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6860\n",
      "Epoch [2/100], Loss: 0.4918\n",
      "Epoch [3/100], Loss: 0.4663\n",
      "Epoch [4/100], Loss: 0.4625\n",
      "Epoch [5/100], Loss: 0.4481\n",
      "Epoch [6/100], Loss: 0.4510\n",
      "Epoch [7/100], Loss: 0.4638\n",
      "Epoch [8/100], Loss: 0.4449\n",
      "Epoch [9/100], Loss: 0.4519\n",
      "Epoch [10/100], Loss: 0.4502\n",
      "Epoch [11/100], Loss: 0.4511\n",
      "Epoch [12/100], Loss: 0.4500\n",
      "Epoch [13/100], Loss: 0.4466\n",
      "Epoch [14/100], Loss: 0.4370\n",
      "Epoch [15/100], Loss: 0.4427\n",
      "Epoch [16/100], Loss: 0.4283\n",
      "Epoch [17/100], Loss: 0.4357\n",
      "Epoch [18/100], Loss: 0.4355\n",
      "Epoch [19/100], Loss: 0.4306\n",
      "Epoch [20/100], Loss: 0.4215\n",
      "Epoch [21/100], Loss: 0.4201\n",
      "Epoch [22/100], Loss: 0.4214\n",
      "Epoch [23/100], Loss: 0.4181\n",
      "Epoch [24/100], Loss: 0.4277\n",
      "Epoch [25/100], Loss: 0.4260\n",
      "Epoch [26/100], Loss: 0.4144\n",
      "Epoch [27/100], Loss: 0.4110\n",
      "Epoch [28/100], Loss: 0.4062\n",
      "Epoch [29/100], Loss: 0.4297\n",
      "Epoch [30/100], Loss: 0.4043\n",
      "Epoch [31/100], Loss: 0.4026\n",
      "Epoch [32/100], Loss: 0.4056\n",
      "Epoch [33/100], Loss: 0.4095\n",
      "Epoch [34/100], Loss: 0.4153\n",
      "Epoch [35/100], Loss: 0.4010\n",
      "Epoch [36/100], Loss: 0.4064\n",
      "Epoch [37/100], Loss: 0.3980\n",
      "Epoch [38/100], Loss: 0.4044\n",
      "Epoch [39/100], Loss: 0.4017\n",
      "Epoch [40/100], Loss: 0.3906\n",
      "Epoch [41/100], Loss: 0.3979\n",
      "Epoch [42/100], Loss: 0.3961\n",
      "Epoch [43/100], Loss: 0.3860\n",
      "Epoch [44/100], Loss: 0.3964\n",
      "Epoch [45/100], Loss: 0.3854\n",
      "Epoch [46/100], Loss: 0.4024\n",
      "Epoch [47/100], Loss: 0.3897\n",
      "Epoch [48/100], Loss: 0.3894\n",
      "Epoch [49/100], Loss: 0.3906\n",
      "Epoch [50/100], Loss: 0.3932\n",
      "Epoch [51/100], Loss: 0.3916\n",
      "Epoch [52/100], Loss: 0.4093\n",
      "Epoch [53/100], Loss: 0.3889\n",
      "Epoch [54/100], Loss: 0.3843\n",
      "Epoch [55/100], Loss: 0.3821\n",
      "Epoch [56/100], Loss: 0.3873\n",
      "Epoch [57/100], Loss: 0.3875\n",
      "Epoch [58/100], Loss: 0.3942\n",
      "Epoch [59/100], Loss: 0.3927\n",
      "Epoch [60/100], Loss: 0.3909\n",
      "Epoch [61/100], Loss: 0.3862\n",
      "Epoch [62/100], Loss: 0.3877\n",
      "Epoch [63/100], Loss: 0.3929\n",
      "Epoch [64/100], Loss: 0.3921\n",
      "Epoch [65/100], Loss: 0.3818\n",
      "Epoch [66/100], Loss: 0.3939\n",
      "Epoch [67/100], Loss: 0.3951\n",
      "Epoch [68/100], Loss: 0.4060\n",
      "Epoch [69/100], Loss: 0.4041\n",
      "Epoch [70/100], Loss: 0.3804\n",
      "Epoch [71/100], Loss: 0.4144\n",
      "Epoch [72/100], Loss: 0.4018\n",
      "Epoch [73/100], Loss: 0.3960\n",
      "Epoch [74/100], Loss: 0.3852\n",
      "Epoch [75/100], Loss: 0.3853\n",
      "Epoch [76/100], Loss: 0.3942\n",
      "Epoch [77/100], Loss: 0.3836\n",
      "Epoch [78/100], Loss: 0.4035\n",
      "Epoch [79/100], Loss: 0.3916\n",
      "Epoch [80/100], Loss: 0.3930\n",
      "Epoch [81/100], Loss: 0.3959\n",
      "Epoch [82/100], Loss: 0.3859\n",
      "Epoch [83/100], Loss: 0.4031\n",
      "Epoch [84/100], Loss: 0.3853\n",
      "Epoch [85/100], Loss: 0.3950\n",
      "Epoch [86/100], Loss: 0.3951\n",
      "Epoch [87/100], Loss: 0.3873\n",
      "Epoch [88/100], Loss: 0.3767\n",
      "Epoch [89/100], Loss: 0.3833\n",
      "Epoch [90/100], Loss: 0.3808\n",
      "Epoch [91/100], Loss: 0.3833\n",
      "Epoch [92/100], Loss: 0.3876\n",
      "Epoch [93/100], Loss: 0.3775\n",
      "Epoch [94/100], Loss: 0.3819\n",
      "Epoch [95/100], Loss: 0.3938\n",
      "Epoch [96/100], Loss: 0.3831\n",
      "Epoch [97/100], Loss: 0.3821\n",
      "Epoch [98/100], Loss: 0.3747\n",
      "Epoch [99/100], Loss: 0.3777\n",
      "Epoch [100/100], Loss: 0.3784\n",
      "Test Accuracy: 0.8306\n"
     ]
    }
   ],
   "source": [
    "# 定义神经网络模型\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        y = x\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x, y\n",
    "\n",
    "# 初始化神经网络\n",
    "net_model = NeuralNetwork()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net_model.parameters(), lr=0.001)\n",
    "\n",
    "# 将数据转换为 DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 训练神经网络\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    net_model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs, layer = net_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# 测试神经网络\n",
    "net_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred, layer = net_model(X_test)\n",
    "    y_pred_class = (y_pred >= 0.5).float()\n",
    "    accuracy = (y_pred_class == y_test).float().mean()\n",
    "    print(f\"Test Accuracy: {accuracy.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "_cell_guid": "bf9d9107-f0c3-4ca9-8c23-a0976193c974",
    "_uuid": "303bb115-faee-4812-819b-e191be9287ce",
    "execution": {
     "iopub.execute_input": "2023-07-13T01:05:16.509072Z",
     "iopub.status.busy": "2023-07-13T01:05:16.508578Z",
     "iopub.status.idle": "2023-07-13T01:05:16.526826Z",
     "shell.execute_reply": "2023-07-13T01:05:16.525265Z",
     "shell.execute_reply.started": "2023-07-13T01:05:16.509029Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "params_lgb = {\n",
    "    'objective': 'binary',  # 二分类目标函数\n",
    "    'metric': 'binary_logloss',  # 二分类损失函数\n",
    "    'boosting_type': 'gbdt',  # 提升类型，可选参数：'gbdt', 'dart', 'goss'\n",
    "    'num_leaves': 28,  # 叶子节点数量\n",
    "    'learning_rate': 0.1,  # 学习率\n",
    "    'feature_fraction': 0.85,  # 特征采样比例\n",
    "    'bagging_fraction': 0.7,  # 数据采样比例\n",
    "    'bagging_freq': 4,  # 数据采样频率\n",
    "    'random_state': 42,\n",
    "    'min_child_samples': 8,\n",
    "    'verbose':-1, \n",
    "    'random_state':12\n",
    "}\n",
    "params_cat = {\n",
    "    'iterations': 626,\n",
    "    'learning_rate': 0.01,\n",
    "    'depth': 4,\n",
    "    'l2_leaf_reg': 0.27,\n",
    "    'border_count': 66,\n",
    "    'random_state': 12,\n",
    "    'verbose': False\n",
    "}\n",
    "params_xgb = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': 0.0356,\n",
    "    'max_depth': 7,\n",
    "    'subsample': 0.95,\n",
    "    'colsample_bytree': 0.92,\n",
    "    'gamma': 9e-08,\n",
    "    'random_state': 12\n",
    "}\n",
    "params_RF = {\n",
    "    'n_estimators': 300,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 3,\n",
    "    'max_features': 'auto',\n",
    "    'random_state': 12\n",
    "}\n",
    "params_net = {\n",
    "    'hidden_layer_sizes': (200,50), \n",
    "    'activation': 'relu', \n",
    "    'solver': 'adam', \n",
    "    'alpha': 0.004524225053160557, \n",
    "    'batch_size': 'auto', \n",
    "    'learning_rate': 'constant', \n",
    "    'learning_rate_init': 0.0032695885785495216, \n",
    "    'power_t': 0.41229208337868917, \n",
    "    'max_iter': 391, \n",
    "    'shuffle': True, \n",
    "    'random_state': None, \n",
    "    'tol': 0.0002505082147304683, \n",
    "    'verbose': False, \n",
    "    'warm_start': False, \n",
    "    'momentum': 0.8862529058691623, \n",
    "    'nesterovs_momentum': True, \n",
    "    'early_stopping': True, \n",
    "    'validation_fraction': 0.1250369526043429,      \n",
    "    'beta_1': 0.8337047263985674, \n",
    "    'beta_2': 0.9945669606589083, \n",
    "    'epsilon': 1.479694727954582e-09, \n",
    "    'n_iter_no_change': 19, \n",
    "    'max_fun': 16800\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_values(value,thred=best_threshold):\n",
    "    \"\"\"根据阈值映射\"\"\"\n",
    "    if value <= thred:\n",
    "        return 0.5 * (value / thred)\n",
    "    else:\n",
    "        return 0.5 + 0.5 * ((value - thred) / 0.65)\n",
    "y_pred = np.vectorize(map_values)(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "_cell_guid": "2e1f3a64-7179-45a7-9d3d-f1b6255ea8bb",
    "_uuid": "b0ee8e1b-5480-4505-93ee-78756c06fe26",
    "execution": {
     "iopub.execute_input": "2023-07-13T01:05:16.531919Z",
     "iopub.status.busy": "2023-07-13T01:05:16.531391Z",
     "iopub.status.idle": "2023-07-13T01:05:28.710251Z",
     "shell.execute_reply": "2023-07-13T01:05:28.708945Z",
     "shell.execute_reply.started": "2023-07-13T01:05:16.531860Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.85, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       101\n",
      "           1       1.00      0.91      0.95        23\n",
      "\n",
      "    accuracy                           0.98       124\n",
      "   macro avg       0.99      0.96      0.97       124\n",
      "weighted avg       0.98      0.98      0.98       124\n",
      "\n",
      "0.9741713301764959\n",
      "[LightGBM] [Warning] feature_fraction is set=0.85, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        98\n",
      "           1       0.92      0.92      0.92        26\n",
      "\n",
      "    accuracy                           0.97       124\n",
      "   macro avg       0.95      0.95      0.95       124\n",
      "weighted avg       0.97      0.97      0.97       124\n",
      "\n",
      "0.9866562009419153\n",
      "[LightGBM] [Warning] feature_fraction is set=0.85, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       107\n",
      "           1       0.82      0.88      0.85        16\n",
      "\n",
      "    accuracy                           0.96       123\n",
      "   macro avg       0.90      0.92      0.91       123\n",
      "weighted avg       0.96      0.96      0.96       123\n",
      "\n",
      "0.9807242990654206\n",
      "[LightGBM] [Warning] feature_fraction is set=0.85, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       101\n",
      "           1       0.88      0.64      0.74        22\n",
      "\n",
      "    accuracy                           0.92       123\n",
      "   macro avg       0.90      0.81      0.84       123\n",
      "weighted avg       0.92      0.92      0.91       123\n",
      "\n",
      "0.8879387938793879\n",
      "[LightGBM] [Warning] feature_fraction is set=0.85, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.85\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       102\n",
      "           1       0.89      0.81      0.85        21\n",
      "\n",
      "    accuracy                           0.95       123\n",
      "   macro avg       0.93      0.89      0.91       123\n",
      "weighted avg       0.95      0.95      0.95       123\n",
      "\n",
      "0.96218487394958\n",
      "0.9838709677419355\n",
      "0.29292929292929293\n",
      "CPU times: total: 10.4 s\n",
      "Wall time: 2.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Models = []\n",
    "best_acu = 0\n",
    "best_threshold = 0\n",
    "# 定义交叉验证的折数\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# 定义模型列表\n",
    "models = [\n",
    "    lgb.LGBMClassifier(**params_lgb),\n",
    "    #cb.CatBoostClassifier(**params_cat),\n",
    "    # xgb.XGBClassifier(**params_xgb),\n",
    "    RandomForestClassifier(**params_RF),\n",
    "    # MLPClassifier(**params_net)\n",
    "    # SVC(probability=True, random_state=42)  # 设置 probability=True 以输出概率\n",
    "]\n",
    "\n",
    "for train_index, valid_index in kf.split(X_train):\n",
    "    \n",
    "    X_tr, X_val = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_tr, y_val = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    \n",
    "    # 训练模型\n",
    "    for model in models:\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "    # 预测结果的概率值\n",
    "    y_pred_proba_list = []\n",
    "    for model in models:\n",
    "#         if type(model).__name__ == 'MLPClassifier':\n",
    "#             scaler = StandardScaler()\n",
    "#             features_to_scale = X_val.columns\n",
    "#             X_val[features_to_scale] = scaler.fit_transform(X_val[features_to_scale])\n",
    "        y_pred_proba = model.predict_proba(X_val)[:, 1]  # 取第一列的概率值（正类的概率）\n",
    "        y_pred_proba_list.append(y_pred_proba)\n",
    "        \n",
    "#     for i in range(len(y_pred_proba_list)):\n",
    "#         thresholds = np.linspace(0, 1, 100)\n",
    "#         acu = 0\n",
    "#         thred = 0\n",
    "#         for threshold in thresholds:\n",
    "#             y_pred = np.where(y_pred_proba_list[i] >= threshold, 1, 0)\n",
    "#             accuracy = np.mean(y_pred == y_val)\n",
    "#             if accuracy > acu:\n",
    "#                 acu = accuracy\n",
    "#                 thred = threshold\n",
    "#                 print('acu=', acu)\n",
    "#         y_pred_proba_list[i] = [map_values(j, thred=thred) for j in y_pred_proba_list[i]]\n",
    "            \n",
    "\n",
    "    # 模型融合（平均概率值）\n",
    "    y_pred_ensemble_proba = np.mean(y_pred_proba_list, axis=0)\n",
    "    \n",
    "    #选取最佳阈值\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    temp_acu = 0\n",
    "    temp_thred = 0\n",
    "    for threshold in thresholds:\n",
    "        # 计算最佳阈值\n",
    "        y_pred_ensemble = np.where(y_pred_ensemble_proba >= threshold, 1, 0)\n",
    "        accuracy = np.mean(y_pred_ensemble == y_val)\n",
    "        if accuracy >= temp_acu:\n",
    "            temp_acu = accuracy\n",
    "            temp_thred = threshold\n",
    "            temp_y_pred = y_pred_ensemble\n",
    "    print(classification_report(y_val, temp_y_pred))\n",
    "    print(roc_auc_score(y_val, y_pred_ensemble_proba))\n",
    "    \n",
    "    # 保存最优模型和最优阈值\n",
    "    if temp_acu >= best_acu:\n",
    "        Models = models\n",
    "        best_acu = temp_acu\n",
    "        best_threshold = temp_thred\n",
    "print(best_acu)\n",
    "print(best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GP1\\AppData\\Local\\Temp\\ipykernel_21460\\952655860.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['EJ'][i] = 'A'\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv',index_col=\"Id\")\n",
    "# 填充缺失值为特征的均值\n",
    "for i in range(len(test_df['EJ'])):\n",
    "    if test_df['EJ'][i] != 'A' and test_df['EJ'][i] != 'B':\n",
    "        test_df['EJ'][i] = 'A'\n",
    "test_df['EJ'] = test_df['EJ'].replace({'A':0, 'B':1})\n",
    "test_df = test_df.fillna(mean_values)\n",
    "test_df.replace([np.inf], [np.nan], inplace=True)\n",
    "test_df = test_df.fillna(max_values)\n",
    "test_df.replace([-np.inf], [np.nan], inplace=True)\n",
    "test_df = test_df.fillna(min_values)\n",
    "test_df = test_df.loc[:, selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>BN</th>\n",
       "      <th>...</th>\n",
       "      <th>FI</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00eed32682bb</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28688.18766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.968552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.315851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>010ebe33f668</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02fa521e1838</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>040e15f562a2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>046e85c7cc7f</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               AB           AF   AH         AM   AR   AX         AY   BC  BD   \\\n",
       "Id                                                                              \n",
       "00eed32682bb  0.0  28688.18766  0.0  38.968552  0.0  0.0  10.315851  0.0  0.0   \n",
       "010ebe33f668  0.0      0.00000  0.0   0.000000  0.0  0.0   0.000000  0.0  0.0   \n",
       "02fa521e1838  0.0      0.00000  0.0   0.000000  0.0  0.0   0.000000  0.0  0.0   \n",
       "040e15f562a2  0.0      0.00000  0.0   0.000000  0.0  0.0   0.000000  0.0  0.0   \n",
       "046e85c7cc7f  0.0      0.00000  0.0   0.000000  0.0  0.0   0.000000  0.0  0.0   \n",
       "\n",
       "               BN  ...   FI   FL   FR   FS   GB   GE   GF   GH   GI   GL  \n",
       "Id                 ...                                                    \n",
       "00eed32682bb  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "010ebe33f668  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "02fa521e1838  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "040e15f562a2  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "046e85c7cc7f  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "_cell_guid": "e143921d-d454-47a2-b71b-65545512f587",
    "_uuid": "c8df3e0d-acf1-40db-ad1a-1849c08df9ac",
    "execution": {
     "iopub.execute_input": "2023-07-13T01:35:57.325269Z",
     "iopub.status.busy": "2023-07-13T01:35:57.324837Z",
     "iopub.status.idle": "2023-07-13T01:35:57.385955Z",
     "shell.execute_reply": "2023-07-13T01:35:57.384535Z",
     "shell.execute_reply.started": "2023-07-13T01:35:57.325237Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4623881  0.45415844 0.45415844 0.45415844 0.45415844]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "for model in Models:\n",
    "    y_pred_proba = model.predict_proba(test_df)[:, 1]  # 取第一列的概率值（正类的概率）\n",
    "    y_pred.append(y_pred_proba)\n",
    "\n",
    "# 模型融合（平均概率值）\n",
    "y_pred = np.mean(y_pred, axis=0)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "_cell_guid": "fe24b52e-a9ae-473e-afcc-99c4c714f0ac",
    "_uuid": "4b671f91-d4d7-4f30-9e4c-55d87e7d8093",
    "execution": {
     "iopub.execute_input": "2023-07-13T01:35:57.978839Z",
     "iopub.status.busy": "2023-07-13T01:35:57.978442Z",
     "iopub.status.idle": "2023-07-13T01:35:57.987700Z",
     "shell.execute_reply": "2023-07-13T01:35:57.986189Z",
     "shell.execute_reply.started": "2023-07-13T01:35:57.978809Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44734715 0.55265285]\n",
      " [0.45367766 0.54632234]\n",
      " [0.45367766 0.54632234]\n",
      " [0.45367766 0.54632234]\n",
      " [0.45367766 0.54632234]]\n"
     ]
    }
   ],
   "source": [
    "def map_values(value,thred=best_threshold):\n",
    "    \"\"\"根据阈值映射\"\"\"\n",
    "    if value <= thred:\n",
    "        return 0.5 * (value / thred)\n",
    "    else:\n",
    "        return 0.5 + 0.5 * ((value - thred) / 0.65)\n",
    "y_pred = np.vectorize(map_values)(y_pred)\n",
    "pred = np.stack((1-y_pred, y_pred), axis=1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 2.0, 4.0], [0.0, 3.0, 5.0]]\n"
     ]
    }
   ],
   "source": [
    "a =  [[0., 0.], [2., 3.], [4., 5.]]\n",
    "# 使用zip函数将a列表中的元素重新组合成元组的形式\n",
    "transposed_a = zip(*a)\n",
    "\n",
    "# 使用列表解析，将元组中的元素重新组织成所需的形式\n",
    "result_a = [[item for item in row] for row in transposed_a]\n",
    "print(result_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X = [[0., 0.], [1., 1.], [1., 1.]]\n",
    "y = [0, 1, 1]\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "_cell_guid": "1b50d9ba-ffbd-4f64-b7b7-cc7c260c465c",
    "_uuid": "15b27c60-92ea-46d6-8e1e-cbf0cd1a7854",
    "execution": {
     "iopub.execute_input": "2023-07-13T01:35:58.392196Z",
     "iopub.status.busy": "2023-07-13T01:35:58.391827Z",
     "iopub.status.idle": "2023-07-13T01:35:58.397570Z",
     "shell.execute_reply": "2023-07-13T01:35:58.396176Z",
     "shell.execute_reply.started": "2023-07-13T01:35:58.392169Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame()\n",
    "# submission[\"Id\"] = test_df.index\n",
    "# submission[\"class_0\"] = 1 - y_pred\n",
    "# submission[\"class_1\"] = y_pred\n",
    "# submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T01:35:59.310143Z",
     "iopub.status.busy": "2023-07-13T01:35:59.309706Z",
     "iopub.status.idle": "2023-07-13T01:36:01.356154Z",
     "shell.execute_reply": "2023-07-13T01:36:01.354378Z",
     "shell.execute_reply.started": "2023-07-13T01:35:59.310111Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test[\"Id\"], columns = [\"Id\"]);\n",
    "submission[\"class_0\"] = 1 - y_pred\n",
    "submission[\"class_1\"] = y_pred\n",
    "\n",
    "submission.to_csv('submission.csv', index = None);\n",
    "submission_df = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T01:05:28.875035Z",
     "iopub.status.busy": "2023-07-13T01:05:28.873829Z",
     "iopub.status.idle": "2023-07-13T01:05:28.902151Z",
     "shell.execute_reply": "2023-07-13T01:05:28.900997Z",
     "shell.execute_reply.started": "2023-07-13T01:05:28.874991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.447347</td>\n",
       "      <td>0.552653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.453678</td>\n",
       "      <td>0.546322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.453678</td>\n",
       "      <td>0.546322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.453678</td>\n",
       "      <td>0.546322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.453678</td>\n",
       "      <td>0.546322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.447347  0.552653\n",
       "1  010ebe33f668  0.453678  0.546322\n",
       "2  02fa521e1838  0.453678  0.546322\n",
       "3  040e15f562a2  0.453678  0.546322\n",
       "4  046e85c7cc7f  0.453678  0.546322"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
